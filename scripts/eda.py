import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# ===================================================================
# ì„¤ì •: ë¶„ì„í•  íŒŒì¼ê³¼ ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œë¥¼ ì§ì ‘ ì§€ì •í•©ë‹ˆë‹¤.
# ===================================================================
COUNTS_PATH = "../results/count_matrix_annotated.csv"
METADATA_PATH = "../data/GSE288534_meta.csv"
RESULTS_DIR = "../results/"


# ===================================================================

def run_eda():
    """
    EDA, ì „ì²˜ë¦¬, ìµœì¢… PCA ì‹œê°í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    print("ğŸš€ EDA ë° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")

    # --- 1. ë°ì´í„° ë¡œë”© ---
    try:
        counts_df = pd.read_csv(COUNTS_PATH, index_col=0)
        metadata_df = pd.read_csv(METADATA_PATH, index_col=0)
    except FileNotFoundError as e:
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. '{e.filename}'")
        return

    # --- 2. ì›ë³¸ ë°ì´í„° ìš”ì•½ (Transcript ìˆ˜ì¤€) ---
    print("\n" + "=" * 50)
    print("ğŸ“Š 2. ì›ë³¸ ë°ì´í„° ìš”ì•½ (Transcript ìˆ˜ì¤€)")
    print("=" * 50)
    print("\n--- [ì›ë³¸ target_id (ì „ì‚¬ì²´) ìš”ì•½] ---")
    unique_ids = counts_df.index.nunique()
    print(f"  - ê³ ìœ í•œ target_id ìˆ˜: {unique_ids}ê°œ")
    print("\n--- [ì›ë³¸ gene_symbol (ìœ ì „ì) ìš”ì•½] ---")
    unique_symbols = counts_df[counts_df['gene_symbol'] != 'N/A']['gene_symbol'].nunique()
    print(f"  - ê³ ìœ í•œ gene_symbol ìˆ˜: {unique_symbols}ê°œ")

    # --- 3. ìƒ˜í”Œë³„ ë°œí˜„ ìœ ì „ì ìˆ˜ ìš”ì•½ ---
    print("\n" + "=" * 50)
    print("ğŸ§¬ 3. ìƒ˜í”Œë³„ ë°œí˜„ ìœ ì „ì ìˆ˜ ìš”ì•½ (Count > 0)")
    print("=" * 50)
    count_columns = [col for col in counts_df.columns if col != 'gene_symbol']
    for sample in count_columns:
        expressed_mask = counts_df[sample] > 0
        expressed_target_ids = expressed_mask.sum()
        expressed_symbols = counts_df.loc[expressed_mask & (counts_df['gene_symbol'] != 'N/A'), 'gene_symbol'].nunique()
        print(f"  - [{sample}]: target_id {expressed_target_ids}ê°œ / gene_symbol {expressed_symbols}ê°œ")

    # --- 4. 1ì°¨ ì „ì²˜ë¦¬: ë°œí˜„ëŸ‰ ì—†ëŠ” ì „ì‚¬ì²´ ì œê±° ---
    print("\n" + "=" * 50)
    print("ğŸ› ï¸  4. 1ì°¨ ì „ì²˜ë¦¬: ë°œí˜„ëŸ‰ ì—†ëŠ” ì „ì‚¬ì²´(target_id) ì œê±°")
    print("=" * 50)
    original_transcript_count = len(counts_df)
    original_symbol_count = counts_df[counts_df['gene_symbol'] != 'N/A']['gene_symbol'].nunique()
    genes_to_keep = counts_df[count_columns].sum(axis=1) > 0
    transcript_filtered_df = counts_df[genes_to_keep]
    filtered_transcript_count = len(transcript_filtered_df)
    num_removed = original_transcript_count - filtered_transcript_count
    print(f"  - ëª¨ë“  ìƒ˜í”Œì—ì„œ ë°œí˜„ëŸ‰ì´ 0ì¸ target_id {num_removed}ê°œë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
    filtered_symbol_count = transcript_filtered_df[transcript_filtered_df['gene_symbol'] != 'N/A'][
        'gene_symbol'].nunique()
    print("\n--- [ì „ì²˜ë¦¬ ì „/í›„ ID ê°œìˆ˜ ë¹„êµ] ---")
    print(f"  - target_id: {original_transcript_count}ê°œ  ->  {filtered_transcript_count}ê°œ")
    print(f"  - gene_symbol: {original_symbol_count}ê°œ  ->  {filtered_symbol_count}ê°œ")

    # --- 5. 2ì°¨ ì „ì²˜ë¦¬: Gene Symbol ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ìµœì¢… ì§‘ê³„ ---
    print("\n" + "=" * 50)
    print("âœ¨ 5. 2ì°¨ ì „ì²˜ë¦¬: Gene Symbol ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ìµœì¢… ì§‘ê³„")
    print("=" * 50)
    known_genes_df = transcript_filtered_df[transcript_filtered_df['gene_symbol'] != 'N/A']
    gene_level_counts = known_genes_df.groupby('gene_symbol').sum()
    print(f"  - ìµœì¢… ë¶„ì„ì— ì‚¬ìš©ë  ê³ ìœ  ìœ ì „ì(gene_symbol)ì˜ ìˆ˜: {len(gene_level_counts)}ê°œ")

    # --- 6. ìµœì¢… ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ---
    print("\n" + "=" * 50)
    print("ğŸ’¾ 6. ìµœì¢… ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ë¡œ ì €ì¥")
    print("=" * 50)
    output_path = os.path.join(RESULTS_DIR, 'count_matrix_preprocessed.csv')
    gene_level_counts.to_csv(output_path)
    print(f"  âœ… ìµœì¢… ì „ì²˜ë¦¬ëœ ë°ì´í„°(Gene ìˆ˜ì¤€)ê°€ ë‹¤ìŒ ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\n     {output_path}")

    # --- 7. PCA ë¶„ì„ ë° ì‹œê°í™” (Gene ìˆ˜ì¤€ ë°ì´í„° ì‚¬ìš©) ---
    print("\n" + "=" * 50)
    print("ğŸ“ˆ 7. PCA ë¶„ì„ ë° ì‹œê°í™” (ìƒ˜í”Œ í´ëŸ¬ìŠ¤í„°ë§ í™•ì¸)")
    print("=" * 50)

    # PCAë¥¼ ìœ„í•´ ë°ì´í„°ë¥¼ ì „ì¹˜ (ìƒ˜í”Œ x ìœ ì „ì)í•˜ê³  log ë³€í™˜ ë° í‘œì¤€í™”
    log_transformed_data = np.log1p(gene_level_counts.T)
    scaled_data = StandardScaler().fit_transform(log_transformed_data)

    pca = PCA(n_components=2)
    principal_components = pca.fit_transform(scaled_data)

    pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'], index=metadata_df.index)
    pca_df = pd.concat([pca_df, metadata_df], axis=1)

    plt.figure(figsize=(10, 8))
    sns.scatterplot(x='PC1', y='PC2', hue='condition', data=pca_df, s=150, alpha=0.8)

    for i in range(pca_df.shape[0]):
        plt.text(pca_df['PC1'][i] + 0.3, pca_df['PC2'][i] + 0.3, pca_df.index[i], fontsize=9)

    plt.title('PCA of Samples (Control vs Experimental)', fontsize=16)
    plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=12)
    plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=12)
    plt.legend(title='Condition')
    plt.grid(True, linestyle='--', alpha=0.6)

    pca_plot_path = os.path.join(RESULTS_DIR, 'pca_plot_eda.png')
    plt.savefig(pca_plot_path)
    print(f"  âœ… PCA Plotì´ ë‹¤ìŒ ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\n     {pca_plot_path}")
    plt.close()

    print("\n--- EDA ë° ì „ì²˜ë¦¬ ì¢…ë£Œ ---")


if __name__ == '__main__':
    run_eda()
